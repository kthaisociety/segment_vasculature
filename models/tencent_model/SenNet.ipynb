{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/segment_vasculature/models\n"
     ]
    }
   ],
   "source": [
    "# Hack to import helper packages\n",
    "%cd /workspaces/segment_vasculature/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.loss_functions import DiceLoss\n",
    "from helpers.train_test import train_and_test\n",
    "from helpers.dataset_setup import train_test_split, augment_image, DataLoader, TRAIN_FOLDER, preprocess_image, preprocess_mask\n",
    "\n",
    "from resnet import resnet50, resnet10\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import cv2\n",
    "#import wandb\n",
    "from skimage.transform import resize as skresize\n",
    "#wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = f'{TRAIN_FOLDER}/kidney_2/images/'\n",
    "image_files = [os.path.join(image_folder, img) for img in os.listdir(image_folder) if img.endswith(\".tif\")]\n",
    "image_files.sort()\n",
    "labels_folder = f'{TRAIN_FOLDER}/kidney_2/labels/'\n",
    "label_files = [os.path.join(labels_folder, img) for img in os.listdir(labels_folder) if img.endswith(\".tif\")]\n",
    "label_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(paths: list[str]) -> torch.Tensor:\n",
    "    imgs = []\n",
    "    for path in paths:\n",
    "        img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "        # img = np.tile(img[...,None],[1,1,3])\n",
    "        img = img.astype('float32')\n",
    "        mx = np.max(img)\n",
    "        if mx:\n",
    "            img/=mx\n",
    "        # img = np.transpose(img,(2,0,1))\n",
    "        imgs.append(torch.tensor(img))\n",
    "    img_ten = torch.stack(imgs)\n",
    "    return img_ten\n",
    "\n",
    "def preprocess_mask(paths: list[str]) -> torch.Tensor:\n",
    "    msks = []\n",
    "    for path in paths:\n",
    "        msk = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "        msk = msk.astype('float32')\n",
    "        msk/=255.0\n",
    "        msks.append(torch.tensor(msk))\n",
    "    msk_ten = torch.stack(msks)\n",
    "    return msk_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SenNetDataset(Dataset):\n",
    "\n",
    "    def __init__(self, image_files: list[str], mask_files, input_size=(16, 256, 256), augmentation_transforms=None):\n",
    "        self.image_files=image_files\n",
    "        self.mask_files=mask_files\n",
    "        self.input_D = input_size[0]\n",
    "        self.input_H = input_size[1]\n",
    "        self.input_W = input_size[2]\n",
    "        self.augmentation_transforms=augmentation_transforms\n",
    "        self.iter = 0\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        print(\"idx: \", idx)\n",
    "        image_paths = self.image_files[idx]\n",
    "        mask_paths = self.mask_files[idx]\n",
    "        # Extract images into tensor\n",
    "        images = preprocess_image(image_paths)\n",
    "        masks = preprocess_mask(mask_paths)\n",
    "        img_size = list(images.size())\n",
    "        mask_size = list(masks.size())\n",
    "        assert img_size[0] == mask_size[0], \"img size:{} is not equal to mask size:{}\".format(img_size, mask_size)\n",
    "        \n",
    "        print(f\"Image shape: {images.shape}\")\n",
    "        print(f\"Mask shape: {masks.shape}\")\n",
    "        images = images.reshape((1, img_size[0], img_size[1], img_size[2]))\n",
    "        masks = masks.reshape((1, mask_size[0], mask_size[1], mask_size[2]))\n",
    "        print(f\"Image shape: {images.shape}\")\n",
    "        print(f\"Mask shape: {masks.shape}\")\n",
    "        images, masks = self.__training_data_process__(images, masks)\n",
    "        \n",
    "        if self.augmentation_transforms:\n",
    "            image, mask=self.augmentation_transforms(image, mask, self.input_size)\n",
    "\n",
    "        print(f\"Image shape: {images.shape}\")\n",
    "        print(f\"Mask shape: {masks.shape}\")\n",
    "        return images, masks\n",
    "\n",
    "    def __drop_invalid_range__(self, volume, label=None):\n",
    "        \"\"\"\n",
    "        Cut off the invalid area\n",
    "        \"\"\"\n",
    "        zero_value = volume[0, 0, 0]\n",
    "        non_zeros_idx = np.where(volume != zero_value)\n",
    "        \n",
    "        [max_z, max_h, max_w] = np.max(np.array(non_zeros_idx), axis=1)\n",
    "        [min_z, min_h, min_w] = np.min(np.array(non_zeros_idx), axis=1)\n",
    "        \n",
    "        if label is not None:\n",
    "            return volume[min_z:max_z, min_h:max_h, min_w:max_w], label[min_z:max_z, min_h:max_h, min_w:max_w]\n",
    "        else:\n",
    "            return volume[min_z:max_z, min_h:max_h, min_w:max_w]\n",
    "\n",
    "\n",
    "\n",
    "    def __itensity_normalize_one_volume__(self, volume: np.ndarray) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        normalize the itensity of an nd volume based on the mean and std of non-zero region\n",
    "        inputs:\n",
    "            volume: the input nd volume\n",
    "        outputs:\n",
    "            out: the normalized nd volume\n",
    "        \"\"\"\n",
    "        \n",
    "        pixels = volume[volume > 0]\n",
    "        mean = pixels.mean()\n",
    "        std  = pixels.std()\n",
    "        out = (volume - mean)/std\n",
    "        out_random = np.random.normal(0, 1, size = volume.shape)\n",
    "        out[volume == 0] = out_random[volume == 0]\n",
    "        return torch.from_numpy(out)\n",
    "\n",
    "    def __resize_data__(self, data: torch.Tensor, label=False) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Resize the data to the input size\n",
    "        \"\"\" \n",
    "        #scale = [self.input_D*1.0/depth, self.input_H*1.0/height, self.input_W*1.0/width]\n",
    "        np_data = data.numpy()\n",
    "        if label:\n",
    "            data: np.ndarray = skresize(np_data, (1, self.input_D, self.input_H, self.input_W))\n",
    "        else:\n",
    "            data: np.ndarray = skresize(np_data, (1, self.input_D, self.input_H, self.input_W))\n",
    "        \n",
    "        return data\n",
    "\n",
    "\n",
    "    def __crop_data__(self, data, label):\n",
    "        \"\"\"\n",
    "        Random crop with different methods:\n",
    "        \"\"\" \n",
    "        # random center crop\n",
    "        data, label = self.__random_center_crop__ (data, label)\n",
    "        \n",
    "        return data, label\n",
    "\n",
    "    def __training_data_process__(self, data: torch.Tensor, label: torch.Tensor): \n",
    "        # crop data according net input size\n",
    "        # data = data.get_data()\n",
    "        # label = label.get_data()\n",
    "        \n",
    "        # drop out the invalid range\n",
    "        #data, label = self.__drop_invalid_range__(data, label)\n",
    "        \n",
    "        # crop data\n",
    "        #data, label = self.__crop_data__(data, label) \n",
    "\n",
    "        # resize data\n",
    "        data = self.__resize_data__(data, label=False)\n",
    "        label = self.__resize_data__(label, label=True)\n",
    "        # normalization datas\n",
    "        # NOTE: Something drops the required_grad flag here, maybe int casting?\n",
    "        data = self.__itensity_normalize_one_volume__(data)\n",
    "        # label = torch.from_numpy(label)\n",
    "        data.requires_grad = True\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk the data into the desired depth of the 3d image\n",
    "_3d_image_depth = 8\n",
    "_3d_images = []\n",
    "_3d_labels = []\n",
    "for i in range(0, len(image_files), _3d_image_depth):\n",
    "    # TODO: if we need more images, we can slide the window by 1 instead of 16\n",
    "    # Extract images into tensor\n",
    "    images = image_files[i:(i+_3d_image_depth)]\n",
    "    masks = label_files[i:(i+_3d_image_depth)]\n",
    "    _3d_images.append(images)\n",
    "    _3d_labels.append(masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_files, val_image_files, train_mask_files, val_mask_files = train_test_split(\n",
    "    _3d_images, _3d_labels, test_size=0.1, shuffle=False)\n",
    "\n",
    "input_dims = (768, 768)\n",
    "\n",
    "train_dataset = SenNetDataset(train_image_files, train_mask_files, input_size=(_3d_image_depth, input_dims[0], input_dims[1]))\n",
    "val_dataset = SenNetDataset(val_image_files, val_mask_files, input_size=(_3d_image_depth, input_dims[0], input_dims[1]))\n",
    "\n",
    "train_dataloader= DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "dataloaders = {\n",
    "    'train': train_dataloader,\n",
    "    'val': val_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedicalNet(nn.Module):\n",
    "\n",
    "  def __init__(self, path_to_weights, device, kw):\n",
    "    super(MedicalNet, self).__init__()\n",
    "    self.model = resnet10(**kw)\n",
    "    num_seg_classes = kw['num_seg_classes']\n",
    "    self.model.conv_seg = nn.Sequential(\n",
    "        nn.ConvTranspose3d(\n",
    "          in_channels=512,\n",
    "          out_channels=256,\n",
    "          stride=(2, 2, 2),\n",
    "          padding=(1, 1, 1),\n",
    "          dilation=(1, 2, 2),\n",
    "          kernel_size=(3, 2, 2),\n",
    "          output_padding=(1, 1, 1),\n",
    "        ),\n",
    "        nn.BatchNorm3d(256),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.ConvTranspose3d(\n",
    "          in_channels=256,\n",
    "          out_channels=64,\n",
    "          stride=(2, 2, 2),\n",
    "          padding=(1, 1, 1),\n",
    "          dilation=(2, 2, 2),\n",
    "          kernel_size=(4, 2, 2),\n",
    "          output_padding=(1, 1, 1),\n",
    "        ),\n",
    "        nn.BatchNorm3d(64),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.ConvTranspose3d(\n",
    "          in_channels=64,\n",
    "          out_channels=num_seg_classes,\n",
    "          stride=(1, 2, 2),\n",
    "          padding=(1, 1, 1),\n",
    "          dilation=(1, 2, 2),\n",
    "          kernel_size=(3, 2, 2),\n",
    "          output_padding=(0, 1, 1),\n",
    "        ),\n",
    "    )\n",
    "    net_dict = self.model.state_dict()\n",
    "    pretrained_weights = torch.load(path_to_weights, map_location=torch.device(device))\n",
    "    pretrain_dict = {\n",
    "        k.replace(\"module.\", \"\"): v for k, v in pretrained_weights['state_dict'].items() if k.replace(\"module.\", \"\") in net_dict.keys()\n",
    "      }\n",
    "    net_dict.update(pretrain_dict)\n",
    "    self.model.load_state_dict(net_dict)\n",
    "\n",
    "  def forward(self, x: torch.Tensor):\n",
    "    x = self.model(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run = wandb.init(\n",
    "#     project=\"custom_seg_vasculature\",\n",
    "#     config={\n",
    "#         \"architechture\": \"pretrained_resnet50\",\n",
    "#         \"optimizer\": \"ADAM\",\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "idx:  0\n",
      "Image shape: torch.Size([8, 1041, 1511])\n",
      "Mask shape: torch.Size([8, 1041, 1511])\n",
      "Image shape: torch.Size([1, 8, 1041, 1511])\n",
      "Mask shape: torch.Size([1, 8, 1041, 1511])\n",
      "Image shape: torch.Size([1, 8, 768, 768])\n",
      "Mask shape: (1, 8, 768, 768)\n",
      "Input before forward: torch.Size([1, 1, 8, 768, 768])\n",
      "After conv1 shape: torch.Size([1, 64, 4, 384, 384])\n",
      "maxpool shape: torch.Size([1, 64, 2, 192, 192])\n",
      "layer4 shape: torch.Size([1, 512, 1, 96, 96])\n",
      "After conv_seg shape: torch.Size([1, 1, 8, 768, 768])\n",
      "Predicted Mask shape: torch.Size([1, 1, 8, 768, 768])\n",
      "Mask shape: torch.Size([1, 1, 8, 768, 768])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m     trained_model, train_epoch_losses, test_epoch_losses \u001b[38;5;241m=\u001b[39m train_and_test(model, dataloaders, optimizer, criterion, w_b\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_epochs\u001b[38;5;241m=\u001b[39mepochs, show_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trained_model, train_epoch_losses, test_epoch_losses\n\u001b[0;32m---> 20\u001b[0m trained_model, train_epoch_losses, test_epoch_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#torch.save(trained_model.state_dict(), 'lower_learning_rate_100.pth')\u001b[39;00m\n\u001b[1;32m     22\u001b[0m  \n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# input: (1, 1, z, x, y)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# output looks like: (1, 1, 2, x/4, y/4)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[36], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[1;32m     15\u001b[0m criterion \u001b[38;5;241m=\u001b[39m DiceLoss()\n\u001b[0;32m---> 16\u001b[0m trained_model, train_epoch_losses, test_epoch_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_images\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trained_model, train_epoch_losses, test_epoch_losses\n",
      "File \u001b[0;32m/workspaces/segment_vasculature/models/helpers/train_test.py:88\u001b[0m, in \u001b[0;36mtrain_and_test\u001b[0;34m(model, dataloaders, optimizer, criterion, w_b, scheduler, num_epochs, show_images, max_norm)\u001b[0m\n\u001b[1;32m     83\u001b[0m batchsummary[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mphase\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_dice_coeff\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(dice_coeff(y_pred, y_true))\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m#clip_grad_value_(model.parameters(), clip_value=max_norm)\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "def train():\n",
    "    kw = {'sample_input_D': _3d_image_depth, 'sample_input_H': input_dims[0], 'sample_input_W': input_dims[1], 'num_seg_classes': 1}\n",
    "    model = MedicalNet('tencent_model/pretrain/resnet_10.pth', device=\"cuda\", kw=kw)\n",
    "    \n",
    "\n",
    "    for k, v in model.named_parameters():\n",
    "        if k.startswith(\"conv_seg\"):\n",
    "            v.requires_grad = True\n",
    "        else:\n",
    "            v.requires_grad = False\n",
    "\n",
    "    #run.watch(models=model, log=\"all\")\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    criterion = DiceLoss()\n",
    "    trained_model, train_epoch_losses, test_epoch_losses = train_and_test(model, dataloaders, optimizer, criterion, w_b=False, num_epochs=epochs, show_images=False)\n",
    "    return trained_model, train_epoch_losses, test_epoch_losses\n",
    "\n",
    "\n",
    "trained_model, train_epoch_losses, test_epoch_losses = train()\n",
    "#torch.save(trained_model.state_dict(), 'lower_learning_rate_100.pth')\n",
    " \n",
    "# input: (1, 1, z, x, y)\n",
    "# output looks like: (1, 1, 2, x/4, y/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run.finish()\n",
    "# plot the losses\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_epoch_losses, label=\"train\")\n",
    "plt.plot(test_epoch_losses, label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
